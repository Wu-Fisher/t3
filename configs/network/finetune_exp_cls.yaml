# Example network configuration for an object classification finetune task

# Network size corresponds to "t3_medium" but can be overwritten in code
patch_size: 16
encoder_embed_dim: 768
encoder_heads: 12
pooling: "none"
encoder_depth: 3
trunk_depth: 9

encoders:
  wedge:
    _target_: t3.models.ViTEncoder
    patch_size: ${network.patch_size}
    embed_dim: ${network.encoder_embed_dim}
    depth: ${network.encoder_depth}
    num_heads: ${network.encoder_heads}
    mlp_ratio: 4. 
  finray:
    _target_: t3.models.ViTEncoder
    patch_size: ${network.patch_size}
    embed_dim: ${network.encoder_embed_dim}
    depth: ${network.encoder_depth}
    num_heads: ${network.encoder_heads}
    mlp_ratio: 4. 
  svelte:
    _target_: t3.models.ViTEncoder
    patch_size: ${network.patch_size}
    embed_dim: ${network.encoder_embed_dim}
    depth: ${network.encoder_depth}
    num_heads: ${network.encoder_heads}
    mlp_ratio: 4. 
  densetact:
    _target_: t3.models.ViTEncoder
    patch_size: ${network.patch_size}
    embed_dim: ${network.encoder_embed_dim}
    depth: ${network.encoder_depth}
    num_heads: ${network.encoder_heads}
    mlp_ratio: 4. 
  mini:
    _target_: t3.models.ViTEncoder
    patch_size: ${network.patch_size}
    embed_dim: ${network.encoder_embed_dim}
    depth: ${network.encoder_depth}
    num_heads: ${network.encoder_heads}
    mlp_ratio: 4. 

shared_trunk:
  _target_: t3.models.TransformerTrunk
  embed_dim: ${network.encoder_embed_dim}
  depth: ${network.trunk_depth}
  num_heads: ${network.encoder_heads}
  mlp_ratio: 4.
  pooling_type: ${network.pooling}

decoders:
  cls_cnc:
    _target_: t3.models.MLPDecoder
    input_dim: ${network.encoder_embed_dim}
    output_dim: 6
    hidden_dims: [256, 128, 64]
    dropout_p: 0.1
    transformer_upstream: true
    pooling_type: cls
    loss_func:
      _target_: torch.nn.CrossEntropyLoss